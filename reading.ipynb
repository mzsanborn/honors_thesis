{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Graph Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n",
      "d61_6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"regular_graphs\"\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "            if con == 0: \n",
    "                continue\n",
    "            if amplification > 500: \n",
    "                continue\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/regular_graphs_output\", \"params.csv\", \"results/regular_graphs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Graphs 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d4_f0.1\n",
      "d4_f0.16\n",
      "d4_f0.14\n",
      "d4_f0.14\n",
      "d4_f0.21\n",
      "d4_f0.1\n",
      "d4_f0.16\n",
      "d4_f0.1\n",
      "d4_f0.21\n",
      "d4_f0.21\n",
      "d4_f0.16\n",
      "d4_f0.1\n",
      "d4_f0.14\n",
      "d4_f0.21\n",
      "d4_f0.14\n",
      "d4_f0.16\n",
      "d4_f0.1\n",
      "d4_f0.14\n",
      "d4_f0.16\n",
      "d4_f0.21\n",
      "d4_f0.1\n",
      "d4_f0.1\n",
      "d4_f0.16\n",
      "d4_f0.16\n",
      "d4_f0.14\n",
      "d4_f0.14\n",
      "d4_f0.21\n",
      "d4_f0.14\n",
      "d4_f0.16\n",
      "d4_f0.21\n",
      "d4_f0.21\n",
      "d4_f0.1\n",
      "d4_f0.14\n",
      "d4_f0.21\n",
      "d4_f0.21\n",
      "d4_f0.14\n",
      "d4_f0.1\n",
      "d4_f0.1\n",
      "d4_f0.16\n",
      "d4_f0.16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"regular_graphs_4\"\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, frac = graph_name.rsplit(\"_\", 1)\n",
    "        frac = frac.replace(\"f\", \"\")\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"frac_triangle\": frac,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/regular_graphs_4_output\", \"params.csv\", \"results/regular_graphs_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Graphs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    \n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"regular_graphs_10\"\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, frac = graph_name.rsplit(\"_\", 1)\n",
    "        frac = frac.replace(\"f\", \"\")\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"frac_triangle\": frac,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/regular_graphs_10_output\", \"params.csv\", \"results/regular_graphs_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Random 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_geometric_0.96_8\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.96_8\n",
      "random_geometric_0.95_10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"random_geometric_1\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _ , radius, _ = graph_name.rsplit(\"_\", 2)\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"radius\": radius,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/random_geometric_1_output\", \"params.csv\", \"results/random_geometric_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Random 2 by jump kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_geometric_0.2_22\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.5_50\n",
      "random_geometric_2.5_9\n",
      "random_geometric_3.0_2\n",
      "random_geometric_3.0_39\n",
      "random_geometric_2.0_15\n",
      "random_geometric_4.5_16\n",
      "random_geometric_4.5_16\n",
      "random_geometric_3.0_2\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.2_21\n",
      "random_geometric_0.2_21\n",
      "random_geometric_0.2_22\n",
      "random_geometric_2.5_9\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_3.0_39\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_2.0_15\n",
      "random_geometric_4.0_23\n",
      "random_geometric_3.0_2\n",
      "random_geometric_4.0_23\n",
      "random_geometric_2.0_15\n",
      "random_geometric_2.5_9\n",
      "random_geometric_0.2_21\n",
      "random_geometric_0.2_22\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_21\n",
      "random_geometric_2.0_15\n",
      "random_geometric_2.0_15\n",
      "random_geometric_4.0_23\n",
      "random_geometric_1.0_47\n",
      "random_geometric_3.0_2\n",
      "random_geometric_3.0_39\n",
      "random_geometric_1.25_24\n",
      "random_geometric_0.2_36\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_2.5_9\n",
      "random_geometric_4.0_23\n",
      "random_geometric_4.5_16\n",
      "random_geometric_3.0_39\n",
      "random_geometric_0.2_21\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_22\n",
      "random_geometric_0.5_50\n",
      "random_geometric_2.5_9\n",
      "random_geometric_3.0_2\n",
      "random_geometric_4.5_16\n",
      "random_geometric_1.0_47\n",
      "random_geometric_0.2_22\n",
      "random_geometric_1.25_24\n",
      "random_geometric_3.0_39\n",
      "random_geometric_4.5_16\n",
      "random_geometric_4.0_23\n",
      "random_geometric_2.5_9\n",
      "random_geometric_0.2_22\n",
      "random_geometric_4.5_16\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.2_22\n",
      "random_geometric_0.2_21\n",
      "random_geometric_4.0_23\n",
      "random_geometric_3.0_39\n",
      "random_geometric_0.5_50\n",
      "random_geometric_3.0_39\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_4.5_16\n",
      "random_geometric_2.0_15\n",
      "random_geometric_0.2_21\n",
      "random_geometric_2.5_9\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_36\n",
      "random_geometric_4.0_23\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.2_22\n",
      "random_geometric_2.5_9\n",
      "random_geometric_4.5_16\n",
      "random_geometric_1.25_24\n",
      "random_geometric_1.0_47\n",
      "random_geometric_3.0_39\n",
      "random_geometric_2.0_15\n",
      "random_geometric_0.2_21\n",
      "random_geometric_3.0_2\n",
      "random_geometric_4.0_23\n",
      "random_geometric_3.0_2\n",
      "random_geometric_2.5_9\n",
      "random_geometric_2.5_9\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_36\n",
      "random_geometric_0.2_36\n",
      "random_geometric_2.0_15\n",
      "random_geometric_0.2_21\n",
      "random_geometric_4.0_23\n",
      "random_geometric_3.0_2\n",
      "random_geometric_2.0_15\n",
      "random_geometric_4.5_16\n",
      "random_geometric_3.0_2\n",
      "random_geometric_1.0_47\n",
      "random_geometric_1.25_24\n",
      "random_geometric_0.5_50\n",
      "random_geometric_0.2_22\n",
      "random_geometric_0.2_22\n",
      "random_geometric_0.2_21\n",
      "random_geometric_4.5_16\n",
      "random_geometric_4.0_23\n",
      "random_geometric_3.0_2\n",
      "random_geometric_2.0_15\n",
      "random_geometric_3.0_39\n",
      "random_geometric_1.0_47\n",
      "random_geometric_3.0_39\n",
      "random_geometric_1.25_24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"random_geometric_2\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _ , radius, _ = graph_name.rsplit(\"_\", 2)\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        try:\n",
    "            avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "            avg_num_clones = float(lines[1].split(\":\")[1])\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"jump_kernel\": radius,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/random_geometric_2_output\", \"params.csv\", \"results/random_geometric_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"grids\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "        \n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"height\": i,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/grids_output\", \"params.csv\", \"results/grids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_374\n",
      "line_402\n",
      "line_450\n",
      "line_374\n",
      "line_402\n",
      "line_450\n",
      "line_157\n",
      "line_308\n",
      "line_487\n",
      "line_336\n",
      "line_309\n",
      "line_136\n",
      "line_415\n",
      "line_364\n",
      "line_361\n",
      "line_38\n",
      "line_362\n",
      "line_361\n",
      "line_308\n",
      "line_452\n",
      "line_157\n",
      "line_38\n",
      "line_353\n",
      "line_34\n",
      "line_160\n",
      "line_464\n",
      "line_134\n",
      "line_312\n",
      "line_347\n",
      "line_134\n",
      "line_461\n",
      "line_73\n",
      "line_461\n",
      "line_385\n",
      "line_35\n",
      "line_48\n",
      "line_136\n",
      "line_335\n",
      "line_217\n",
      "line_336\n",
      "line_157\n",
      "line_335\n",
      "line_217\n",
      "line_415\n",
      "line_364\n",
      "line_309\n",
      "line_38\n",
      "line_487\n",
      "line_385\n",
      "line_487\n",
      "line_309\n",
      "line_404\n",
      "line_48\n",
      "line_452\n",
      "line_404\n",
      "line_308\n",
      "line_362\n",
      "line_464\n",
      "line_48\n",
      "line_347\n",
      "line_312\n",
      "line_136\n",
      "line_160\n",
      "line_385\n",
      "line_353\n",
      "line_34\n",
      "line_427\n",
      "line_134\n",
      "line_35\n",
      "line_427\n",
      "line_73\n",
      "line_160\n",
      "line_38\n",
      "line_487\n",
      "line_362\n",
      "line_309\n",
      "line_353\n",
      "line_404\n",
      "line_34\n",
      "line_487\n",
      "line_309\n",
      "line_374\n",
      "line_335\n",
      "line_450\n",
      "line_217\n",
      "line_336\n",
      "line_402\n",
      "line_415\n",
      "line_364\n",
      "line_217\n",
      "line_335\n",
      "line_73\n",
      "line_452\n",
      "line_404\n",
      "line_361\n",
      "line_73\n",
      "line_427\n",
      "line_464\n",
      "line_160\n",
      "line_347\n",
      "line_312\n",
      "line_136\n",
      "line_160\n",
      "line_34\n",
      "line_353\n",
      "line_362\n",
      "line_461\n",
      "line_385\n",
      "line_35\n",
      "line_48\n",
      "line_427\n",
      "line_464\n",
      "line_452\n",
      "line_347\n",
      "line_312\n",
      "line_361\n",
      "line_157\n",
      "line_450\n",
      "line_374\n",
      "line_335\n",
      "line_38\n",
      "line_217\n",
      "line_157\n",
      "line_402\n",
      "line_35\n",
      "line_415\n",
      "line_308\n",
      "line_364\n",
      "line_374\n",
      "line_450\n",
      "line_308\n",
      "line_336\n",
      "line_402\n",
      "line_362\n",
      "line_361\n",
      "line_404\n",
      "line_336\n",
      "line_461\n",
      "line_136\n",
      "line_364\n",
      "line_415\n",
      "line_35\n",
      "line_353\n",
      "line_34\n",
      "line_385\n",
      "line_48\n",
      "line_312\n",
      "line_347\n",
      "line_452\n",
      "line_464\n",
      "line_461\n",
      "line_134\n",
      "line_73\n",
      "line_427\n",
      "line_134\n",
      "line_404\n",
      "line_452\n",
      "line_362\n",
      "line_308\n",
      "line_402\n",
      "line_336\n",
      "line_461\n",
      "line_374\n",
      "line_450\n",
      "line_415\n",
      "line_364\n",
      "line_217\n",
      "line_336\n",
      "line_335\n",
      "line_364\n",
      "line_415\n",
      "line_487\n",
      "line_38\n",
      "line_309\n",
      "line_361\n",
      "line_38\n",
      "line_452\n",
      "line_157\n",
      "line_35\n",
      "line_73\n",
      "line_427\n",
      "line_464\n",
      "line_134\n",
      "line_361\n",
      "line_347\n",
      "line_312\n",
      "line_464\n",
      "line_136\n",
      "line_34\n",
      "line_160\n",
      "line_353\n",
      "line_347\n",
      "line_312\n",
      "line_136\n",
      "line_35\n",
      "line_450\n",
      "line_374\n",
      "line_461\n",
      "line_402\n",
      "line_361\n",
      "line_362\n",
      "line_452\n",
      "line_335\n",
      "line_217\n",
      "line_427\n",
      "line_308\n",
      "line_487\n",
      "line_309\n",
      "line_336\n",
      "line_374\n",
      "line_450\n",
      "line_415\n",
      "line_364\n",
      "line_157\n",
      "line_402\n",
      "line_404\n",
      "line_362\n",
      "line_461\n",
      "line_35\n",
      "line_134\n",
      "line_73\n",
      "line_48\n",
      "line_385\n",
      "line_353\n",
      "line_404\n",
      "line_48\n",
      "line_385\n",
      "line_34\n",
      "line_464\n",
      "line_34\n",
      "line_353\n",
      "line_347\n",
      "line_312\n",
      "line_217\n",
      "line_427\n",
      "line_335\n",
      "line_73\n",
      "line_160\n",
      "line_404\n",
      "line_308\n",
      "line_362\n",
      "line_361\n",
      "line_487\n",
      "line_309\n",
      "line_362\n",
      "line_217\n",
      "line_38\n",
      "line_335\n",
      "line_160\n",
      "line_374\n",
      "line_450\n",
      "line_157\n",
      "line_402\n",
      "line_48\n",
      "line_385\n",
      "line_160\n",
      "line_427\n",
      "line_461\n",
      "line_73\n",
      "line_134\n",
      "line_73\n",
      "line_309\n",
      "line_385\n",
      "line_34\n",
      "line_487\n",
      "line_353\n",
      "line_48\n",
      "line_34\n",
      "line_353\n",
      "line_136\n",
      "line_157\n",
      "line_134\n",
      "line_361\n",
      "line_38\n",
      "line_452\n",
      "line_404\n",
      "line_452\n",
      "line_487\n",
      "line_38\n",
      "line_309\n",
      "line_374\n",
      "line_450\n",
      "line_402\n",
      "line_415\n",
      "line_217\n",
      "line_364\n",
      "line_336\n",
      "line_308\n",
      "line_335\n",
      "line_415\n",
      "line_364\n",
      "line_336\n",
      "line_48\n",
      "line_461\n",
      "line_385\n",
      "line_136\n",
      "line_35\n",
      "line_308\n",
      "line_35\n",
      "line_427\n",
      "line_134\n",
      "line_157\n",
      "line_464\n",
      "line_347\n",
      "line_312\n",
      "line_160\n",
      "line_136\n",
      "line_464\n",
      "line_347\n",
      "line_312\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"lines_2\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "        \n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"connections\": i,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/lines_2_output\", \"params.csv\", \"results/lines_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fingers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"fingers\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        try:\n",
    "            avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "            avg_num_clones = float(lines[1].split(\":\")[1])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        \n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"connections\": i,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "process_files(\"simulation_results/fingers_output\", \"params.csv\", \"results/fingers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottlenecks 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"bottlenecks_2\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"connections\": i,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"simulation_results/bottlenecks_2_output\", \"params.csv\", \"results/bottlenecks_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottlenecks 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"bottlenecks_4\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"connections\": i,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"simulation_results/bottlenecks_4_output\", \"params.csv\", \"results/bottlenecks_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottlenecks Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck_1\n",
      "bottleneck_1\n",
      "bottleneck_1\n",
      "bottleneck_1\n",
      "bottleneck_1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"bottlenecks_regular\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _, i = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "\n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans, \n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"simulation_results/bottlenecks_regular_output\", \"params.csv\", \"results/bottlenecks_regular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file)\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"PA\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        _ , beta = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"beta\": beta,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"simulation_results/PA_output\", \"params.csv\", \"results/PA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PA Assortative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file, dtype={\"graph_name\": str})\n",
    "    stats_df[\"graph_name\"] = stats_df[\"graph_name\"].str.strip()\n",
    "\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"])\n",
    "    graph_type = \"PA_assortative\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "\n",
    "        graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        #_ , beta = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "\n",
    "\n",
    "        try: \n",
    "            degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "            degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "            amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "            acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "            con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "            trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "            ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "        except KeyError:\n",
    "            print(graph_name)\n",
    "            continue\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"simulation_results/PA_assortative_output\", \"params.csv\", \"results/PA_assortative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PA Regular 2 Regular 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_files(input_folder, stats_file, output_folder=\"results\"):\n",
    "    # Load graph statistics (graph_name is the index)\n",
    "    stats_df = pd.read_csv(stats_file, dtype={\"graph_name\": str})\n",
    "    stats_df[\"graph_name\"] = stats_df[\"graph_name\"].str.strip()\n",
    "\n",
    "    stats_df = stats_df.set_index([\"graph_name\", \"graph_type\"]) \n",
    "    graph_type = \"regular_4_regular_10\"\n",
    "\n",
    "    # Store results separately by mu_rate\n",
    "    results_by_mu = defaultdict(list)\n",
    "    mu_rate = 0\n",
    "    # Loop through all files in the folder\n",
    "    for fname in os.listdir(input_folder):\n",
    "\n",
    "        # Extract graph_name and mu_rate\n",
    "        base = fname.replace(\".txt\", \"\")\n",
    "        #graph_name, mu_rate = base.rsplit(\"_\", 1)\n",
    "        graph_name = base\n",
    "        #_ , beta = graph_name.rsplit(\"_\", 1)\n",
    "\n",
    "        #file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        # Read file and compute averages\n",
    "        #with open(file_path, \"r\") as f:\n",
    "            #lines = f.readlines()\n",
    "        \"\"\"\n",
    "        avg_softsweep_prob = float(lines[0].split(\":\")[1])\n",
    "        avg_num_clones  = float(lines[1].split(\":\")[1])\n",
    "        \"\"\"\n",
    "        avg_softsweep_prob = 0\n",
    "        avg_num_clones  = 0\n",
    "\n",
    "\n",
    "        degree = stats_df.loc[(graph_name, graph_type), \"degree_mean\"]\n",
    "        degree_variance = stats_df.loc[(graph_name, graph_type), \"degree_var\"]\n",
    "        amplification = stats_df.loc[(graph_name, graph_type), \"amp\"]\n",
    "        acc = stats_df.loc[(graph_name, graph_type), \"acc\"]\n",
    "        con = stats_df.loc[(graph_name, graph_type), \"connectivity\"]\n",
    "        trans =  stats_df.loc[(graph_name, graph_type), \"transitivity\"]\n",
    "        ass = stats_df.loc[(graph_name, graph_type), \"degree_assortativity\"]\n",
    "\n",
    "        \n",
    "        results_by_mu[mu_rate].append({\n",
    "            \"file_name\": graph_name,\n",
    "            \"avg_softsweep_prob\": avg_softsweep_prob,\n",
    "            \"avg_num_clones\": avg_num_clones,\n",
    "            \"degree\": degree,\n",
    "            \"degree_variance\": degree_variance,\n",
    "            \"amplification\": amplification,\n",
    "            \"acc\": acc,\n",
    "            \"connectivity\": con, \n",
    "            \"transitivity\": trans,\n",
    "            \"degree_assortativity\": ass \n",
    "        })\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Write one CSV per mu_rate\n",
    "    for mu_rate, rows in results_by_mu.items():\n",
    "        out_path = os.path.join(output_folder, f\"mu{mu_rate}.csv\")\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "process_files(\"graphs/regular_4_regular_10\", \"assortative.csv\", \"results/regular_4_regular_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theis_tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
